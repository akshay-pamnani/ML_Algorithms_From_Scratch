{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b9fe602b-ed51-4b3b-8d63-9942ea5c010e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "\n",
    "class DecisionNode:\n",
    "    def __init__(self, col, split, lchild, rchild):\n",
    "        self.col = col\n",
    "        self.split = split\n",
    "        self.lchild = lchild\n",
    "        self.rchild = rchild\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        # Make decision based upon x_test[col] and split\n",
    "        \n",
    "        if x_test[self.col]>=self.split:\n",
    "            return self.rchild.predict(x_test)\n",
    "        else:\n",
    "            return self.lchild.predict(x_test)\n",
    "        \n",
    "\n",
    "\n",
    "class LeafNode:\n",
    "    def __init__(self, y, prediction):\n",
    "        \"Create leaf node from y values and prediction; prediction is mean(y) or mode(y)\"\n",
    "        self.n = len(y)\n",
    "        self.prediction = prediction\n",
    "        \n",
    "\n",
    "    def predict(self, x_test):\n",
    "        return self.prediction\n",
    "        ...\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "def gini(y):\n",
    "    \"\"\"\n",
    "    Return the gini impurity score for values in y\n",
    "    Assume y = {0,1}\n",
    "    Gini = 1 - sum_i p_i^2 where p_i is the proportion of class i in y\n",
    "    \"\"\"\n",
    "    ...\n",
    "    \n",
    "    y=list(y)\n",
    "    p_0=(y.count(0))/len(y)\n",
    "    p_1=(y.count(1))/len(y)\n",
    "    p_0_2=p_0**2\n",
    "    p_1_2=p_1**2\n",
    "    \n",
    "    gini=1-(p_0_2 + p_1_2)\n",
    "    \n",
    "    return gini\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def find_best_split(X, y,loss, min_samples_leaf):\n",
    "    #y_reshape=np.reshape(y,(np.shape(y)[0],1)) #reshaping so that dimensions align\n",
    "    #Xy=np.hstack((X,y_reshape))                #stacking X along with y\n",
    "    loss_list=[]\n",
    "    \n",
    "    feature=-1\n",
    "    split=-1\n",
    "    best_loss=loss(y)\n",
    "        \n",
    "    if loss==np.var:\n",
    "        \n",
    "        for i in range(np.shape(X)[1]):\n",
    "            loss_list_temp=[]\n",
    "            #Xy_t=Xy[:,[i,-1]]                      #stacking columns of X with y, turn by turn\n",
    "            #x_sorted_asc = Xy_t[Xy_t[:, 0].argsort()] #sorting on first column\n",
    "            #for j in range(np.shape(x_sorted_asc[0])):\n",
    "            #print(x_sorted_asc)\n",
    "            #print(np.shape(x_sorted_asc))\n",
    "            split_vals=np.random.choice(X[:,i], size = 11, replace = False, p = None)\n",
    "            for j in split_vals:\n",
    "                \n",
    "                y_left=y[X[:,i]<j]\n",
    "                y_right=y[X[:,i]>=j]\n",
    "                \n",
    "                len1=np.shape(y_left)[0]\n",
    "                len2=np.shape(y_right)[0]\n",
    "                \n",
    "                if (len1 < min_samples_leaf) or (len2 < min_samples_leaf):\n",
    "                    continue\n",
    "                        \n",
    "                else:\n",
    "                    err1=np.var(y_left)\n",
    "                    err2=np.var(y_right)\n",
    "                    #len1=np.shape(x_sorted_asc[:j,1])[0]\n",
    "                    #len2=np.shape(x_sorted_asc[j:,1])[0]\n",
    "            \n",
    "\n",
    "            \n",
    "                    loss=(len1*err1 + len2*err2)/(len1+len2)\n",
    "                    if loss==0:\n",
    "                        return i,j\n",
    "                        break\n",
    "                        \n",
    "                    else:    \n",
    "                        loss_list.append(([loss,i,j]))\n",
    "        \n",
    "            #loss_list.append(loss_list_temp)\n",
    "        \n",
    "        arr=np.array(loss_list)\n",
    "        m=np.min(arr[:,0])  #Min loss \n",
    "        best_split=(arr[arr[:,0]==m][0])\n",
    "        \n",
    "        if m<best_loss:\n",
    "            \n",
    "            #best_split =arr[arr[:,0]==m] \n",
    "            feature=best_split[1]\n",
    "            split=best_split[2]\n",
    "            best_loss=best_split[0]\n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "        return feature,split\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        \n",
    "        for i in range(np.shape(X)[1]):\n",
    "            loss_list_temp=[]\n",
    "            #Xy_t=Xy[:,[i,-1]]                      #stacking columns of X with y, turn by turn\n",
    "            #x_sorted_asc = Xy_t[Xy_t[:, 0].argsort()] #sorting on first column\n",
    "            #for j in range(np.shape(x_sorted_asc[0])):\n",
    "            #print(x_sorted_asc)\n",
    "            #print(np.shape(x_sorted_asc))\n",
    "            split_vals=np.random.choice(X[:,i], size = 11, replace = False, p = None)\n",
    "            for j in split_vals:\n",
    "                \n",
    "                y_left=y[X[:,i]<j]\n",
    "                y_right=y[X[:,i]>=j]\n",
    "                \n",
    "                len1=np.shape(y_left)[0]\n",
    "                len2=np.shape(y_right)[0]\n",
    "                \n",
    "                if (len1 < min_samples_leaf) or (len2 < min_samples_leaf):\n",
    "                    continue\n",
    "                        \n",
    "                else:\n",
    "                    err1=genie(y_left)\n",
    "                    err2=genie(y_right)\n",
    "                    #len1=np.shape(x_sorted_asc[:j,1])[0]\n",
    "                    #len2=np.shape(x_sorted_asc[j:,1])[0]\n",
    "            \n",
    "\n",
    "            \n",
    "                    loss=(len1*err1 + len2*err2)/(len1+len2)\n",
    "                    if loss==0:\n",
    "                        return i,j\n",
    "                        break\n",
    "                        \n",
    "                    else:    \n",
    "                        loss_list.append(([loss,i,j]))\n",
    "                        \n",
    "                        \n",
    "        arr=np.array(loss_list)\n",
    "        m=np.min(arr[:,0])  #Min loss \n",
    "        best_split=(arr[arr[:,0]==m][0])\n",
    "        \n",
    "        if m<best_loss:\n",
    "            \n",
    "            #best_split =arr[arr[:,0]==m] \n",
    "            feature=best_split[1]\n",
    "            split=best_split[2]\n",
    "            best_loss=best_split[0]\n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "        return feature,split\n",
    "                        \n",
    "        \n",
    "           \n",
    "def find_best_split_2(X, y,loss, min_samples_leaf):\n",
    "    \n",
    "    dict_best_split = {\"feature\": -1, \"split\": -1, \"best_loss\": loss(y)}\n",
    "    k = 11\n",
    "\n",
    "    for col_index in range(len(X[0])):\n",
    "        list_candidates = np.random.choice(X[:, col_index], k)\n",
    "        for split_val in list_candidates:\n",
    "            arr_y_left = y[np.where(X[:, col_index] < split_val)]\n",
    "            arr_y_right = y[np.where(X[:, col_index] >= split_val)]\n",
    "\n",
    "            int_yl_cnt = len(arr_y_left)\n",
    "            int_yr_cnt = len(arr_y_right)\n",
    "\n",
    "            if (int_yl_cnt < min_samples_leaf) | (int_yr_cnt < min_samples_leaf):\n",
    "                continue\n",
    "\n",
    "            split_loss = ((int_yl_cnt * loss(arr_y_left)) + (int_yr_cnt * loss(arr_y_right)))/(int_yl_cnt + int_yr_cnt)\n",
    "            if split_loss == 0:\n",
    "                return col_index, split_val\n",
    "            if split_loss < dict_best_split[\"best_loss\"]:\n",
    "                dict_best_split[\"feature\"] = col_index\n",
    "                dict_best_split[\"split\"] = split_val\n",
    "                dict_best_split[\"best_loss\"] = split_loss\n",
    "    return dict_best_split[\"feature\"], dict_best_split[\"split\"]\n",
    "\n",
    "        \n",
    "               \n",
    "            #for split in range(np.min(X_t),np.max(X_t)):    \n",
    "class DecisionTree621:\n",
    "    def __init__(self, min_samples_leaf=1, loss=None):\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.loss = loss # loss function; either np.var for regression or gini for classification\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Create a decision tree fit to (X,y) and save as self.root, the root of\n",
    "        our decision tree, for  either a classifier or regression.  Leaf nodes for classifiers\n",
    "        predict the most common class (the mode) and regressions predict the average y\n",
    "        for observations in that leaf.\n",
    "        This function is a wrapper around fit_() that just stores the tree in self.root.\n",
    "        \"\"\"\n",
    "        self.root = self.fit_(X, y)\n",
    "\n",
    "\n",
    "    def fit_(self, X, y):\n",
    "        \"\"\"\n",
    "        Recursively create and return a decision tree fit to (X,y) for\n",
    "        either a classification or regression.  This function should call self.create_leaf(X,y)\n",
    "        to create the appropriate leaf node, which will invoke either\n",
    "        RegressionTree621.create_leaf() or ClassifierTree621.create_leaf() depending\n",
    "        on the type of self.\n",
    "        This function is not part of the class \"interface\" and is for internal use, but it\n",
    "        embodies the decision tree fitting algorithm.\n",
    "        (Make sure to call fit_() not fit() recursively.)\n",
    "        \"\"\"\n",
    "        ...\n",
    "        \n",
    "        if np.shape(X)[0] <= self.min_samples_leaf or np.shape(np.unique(X, axis=0)[0])==1:\n",
    "            return self.create_leaf(y)\n",
    "        \n",
    "        col,split=find_best_split(X,y,self.loss,self.min_samples_leaf)\n",
    "        \n",
    "        if col==-1:\n",
    "            return self.create_leaf(y)\n",
    "        else:\n",
    "        #node=DecisionNode(col,split,fit_(self,X,y)\n",
    "            y_reshape=np.reshape(y,(np.shape(y)[0],1)) #reshaping so that dimensions align\n",
    "            Xy=np.hstack((X,y_reshape))\n",
    "            \n",
    "            \n",
    "            \n",
    "            lchild=self.fit_(Xy[Xy[:,col]<split][:,:-1],Xy[Xy[:,col]<split][:,-1])\n",
    "            rchild=self.fit_(Xy[Xy[:,col]>=split][:,:-1],Xy[Xy[:,col]>=split][:,-1])\n",
    "            \n",
    "            tree=DecisionNode(col,split,lchild,rchild)\n",
    "            \n",
    "            return tree\n",
    "        \n",
    "                 \n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        Make a prediction for each record in X_test and return as array.\n",
    "        This method is inherited by RegressionTree621 and ClassifierTree621 and\n",
    "        works for both without modification!\n",
    "        \"\"\"\n",
    "        ...\n",
    "        prediction_list=[]\n",
    "        \n",
    "        for x in X_test:\n",
    "            prediction_list.append(self.root.predict(x))\n",
    "        return np.array(prediction_list)\n",
    "        \n",
    "class RegressionTree621(DecisionTree621):\n",
    "    def __init__(self, min_samples_leaf=1):\n",
    "        super().__init__(min_samples_leaf, loss=np.var)\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        \"Return the R^2 of y_test vs predictions for each record in X_test\"\n",
    "        ...\n",
    "        predictions=self.predict(X_test)\n",
    "        \n",
    "        return r2_score(predictions,y_test)\n",
    "\n",
    "    def create_leaf(self, y):\n",
    "        \"\"\"\n",
    "        Return a new LeafNode for regression, passing y and mean(y) to\n",
    "        the LeafNode constructor.\n",
    "        \"\"\"\n",
    "        leaf=LeafNode(y,np.mean(y))\n",
    "        \n",
    "        return leaf\n",
    "        \n",
    "\n",
    "\n",
    "class ClassifierTree621(DecisionTree621):\n",
    "    def __init__(self, min_samples_leaf=1):\n",
    "        super().__init__(min_samples_leaf, loss=gini)\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        \"Return the accuracy_score() of y_test vs predictions for each record in X_test\"\n",
    "        ...\n",
    "        predictions=self.predict(X_test)\n",
    "        \n",
    "        return accuracy_score(predictions,y_test)\n",
    "        \n",
    "        \n",
    "\n",
    "    def create_leaf(self, y):\n",
    "        \"\"\"\n",
    "        Return a new LeafNode for classification, passing y and mode(y) to\n",
    "        the LeafNode constructor. Feel free to use scipy.stats to use the mode function.\n",
    "        \"\"\"\n",
    "        ...\n",
    "        \n",
    "        leaf=LeafNode(y,stats.mode(y).mode[0])\n",
    "        \n",
    "        return leaf\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f42deea8-a10f-4e44-be8c-920e6c6aef67",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1=[]\n",
    "list2=[]\n",
    "for i in range(100):\n",
    " list2.append(find_best_split_2(X,y,np.var,1))\n",
    " list1.append(find_best_split(X,y,np.var,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "bc05ea58-ce76-44f6-b846-168bdcf9baa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12.0, 9.68),\n",
       " (12.0, 9.74),\n",
       " (12.0, 7.85),\n",
       " (12.0, 9.54),\n",
       " (5.0, 6.943),\n",
       " (12.0, 9.88),\n",
       " (5.0, 6.975),\n",
       " (12.0, 9.16),\n",
       " (12.0, 8.93),\n",
       " (12.0, 9.68),\n",
       " (12.0, 9.54),\n",
       " (12.0, 10.19),\n",
       " (5.0, 6.852),\n",
       " (5.0, 6.943),\n",
       " (5.0, 6.98),\n",
       " (12.0, 7.85),\n",
       " (5.0, 6.842),\n",
       " (5.0, 6.98),\n",
       " (12.0, 10.15),\n",
       " (5.0, 6.98),\n",
       " (12.0, 7.53),\n",
       " (5.0, 6.826),\n",
       " (12.0, 10.16),\n",
       " (12.0, 7.73),\n",
       " (12.0, 9.68),\n",
       " (5.0, 6.951),\n",
       " (5.0, 6.833),\n",
       " (12.0, 10.11),\n",
       " (12.0, 7.53),\n",
       " (12.0, 7.85),\n",
       " (5.0, 6.86),\n",
       " (5.0, 6.854),\n",
       " (5.0, 6.975),\n",
       " (12.0, 10.19),\n",
       " (5.0, 6.842),\n",
       " (12.0, 9.97),\n",
       " (12.0, 8.1),\n",
       " (12.0, 9.04),\n",
       " (12.0, 10.16),\n",
       " (12.0, 7.79),\n",
       " (12.0, 9.55),\n",
       " (5.0, 6.98),\n",
       " (5.0, 6.976),\n",
       " (12.0, 9.09),\n",
       " (12.0, 7.9),\n",
       " (12.0, 9.93),\n",
       " (5.0, 6.897),\n",
       " (5.0, 7.088),\n",
       " (5.0, 6.951),\n",
       " (12.0, 9.88),\n",
       " (5.0, 6.975),\n",
       " (5.0, 6.982),\n",
       " (12.0, 7.54),\n",
       " (5.0, 6.982),\n",
       " (5.0, 6.975),\n",
       " (5.0, 6.8),\n",
       " (5.0, 6.957),\n",
       " (5.0, 6.854),\n",
       " (12.0, 9.04),\n",
       " (12.0, 7.56),\n",
       " (5.0, 6.826),\n",
       " (5.0, 6.968),\n",
       " (5.0, 6.852),\n",
       " (12.0, 10.19),\n",
       " (5.0, 6.849),\n",
       " (5.0, 6.816),\n",
       " (12.0, 9.67),\n",
       " (5.0, 6.939),\n",
       " (5.0, 6.826),\n",
       " (5.0, 6.951),\n",
       " (5.0, 6.98),\n",
       " (5.0, 6.871),\n",
       " (12.0, 9.47),\n",
       " (5.0, 6.975),\n",
       " (12.0, 7.79),\n",
       " (12.0, 9.55),\n",
       " (12.0, 10.21),\n",
       " (12.0, 9.62),\n",
       " (5.0, 6.849),\n",
       " (5.0, 6.98),\n",
       " (5.0, 6.982),\n",
       " (5.0, 6.854),\n",
       " (12.0, 7.67),\n",
       " (5.0, 6.824),\n",
       " (5.0, 6.98),\n",
       " (5.0, 6.98),\n",
       " (5.0, 6.879),\n",
       " (12.0, 9.67),\n",
       " (12.0, 8.1),\n",
       " (12.0, 10.13),\n",
       " (12.0, 9.71),\n",
       " (12.0, 9.62),\n",
       " (5.0, 6.833),\n",
       " (5.0, 6.968),\n",
       " (5.0, 6.824),\n",
       " (12.0, 7.19),\n",
       " (12.0, 9.55),\n",
       " (5.0, 6.897),\n",
       " (5.0, 6.951),\n",
       " (5.0, 6.976)]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "abed29e2-dd67-45a0-aa5c-63e91445ac1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12, 9.62),\n",
       " (12, 7.54),\n",
       " (12, 7.67),\n",
       " (12, 9.8),\n",
       " (5, 6.975),\n",
       " (12, 8.05),\n",
       " (12, 9.97),\n",
       " (12, 9.16),\n",
       " (12, 10.19),\n",
       " (5, 6.854),\n",
       " (12, 9.97),\n",
       " (5, 6.871),\n",
       " (5, 7.088),\n",
       " (12, 9.62),\n",
       " (5, 6.826),\n",
       " (12, 7.6),\n",
       " (5, 6.98),\n",
       " (12, 10.26),\n",
       " (5, 6.852),\n",
       " (5, 6.968),\n",
       " (5, 7.014),\n",
       " (12, 9.74),\n",
       " (12, 8.01),\n",
       " (5, 6.98),\n",
       " (5, 6.852),\n",
       " (5, 6.8),\n",
       " (5, 6.957),\n",
       " (12, 9.67),\n",
       " (5, 6.943),\n",
       " (12, 8.05),\n",
       " (5, 7.061),\n",
       " (12, 8.81),\n",
       " (12, 9.64),\n",
       " (5, 7.014),\n",
       " (12, 7.51),\n",
       " (5, 6.939),\n",
       " (12, 9.97),\n",
       " (5, 6.976),\n",
       " (5, 6.98),\n",
       " (5, 7.007),\n",
       " (12, 10.15),\n",
       " (12, 8.94),\n",
       " (5, 6.874),\n",
       " (5, 6.968),\n",
       " (12, 10.11),\n",
       " (5, 6.976),\n",
       " (12, 10.21),\n",
       " (12, 7.67),\n",
       " (12, 9.97),\n",
       " (12, 9.97),\n",
       " (5, 6.976),\n",
       " (12, 7.79),\n",
       " (12, 10.21),\n",
       " (12, 9.64),\n",
       " (5, 6.975),\n",
       " (12, 7.74),\n",
       " (12, 9.69),\n",
       " (12, 9.67),\n",
       " (12, 9.43),\n",
       " (5, 6.98),\n",
       " (5, 6.951),\n",
       " (5, 6.833),\n",
       " (12, 8.88),\n",
       " (5, 6.879),\n",
       " (12, 7.73),\n",
       " (5, 6.854),\n",
       " (12, 9.8),\n",
       " (12, 10.21),\n",
       " (5, 6.943),\n",
       " (5, 6.852),\n",
       " (5, 6.976),\n",
       " (5, 6.849),\n",
       " (5, 6.943),\n",
       " (12, 9.59),\n",
       " (12, 9.55),\n",
       " (5, 6.957),\n",
       " (5, 6.849),\n",
       " (12, 8.26),\n",
       " (5, 7.107),\n",
       " (12, 8.05),\n",
       " (12, 8.94),\n",
       " (5, 6.982),\n",
       " (5, 7.014),\n",
       " (12, 5.25),\n",
       " (5, 6.939),\n",
       " (5, 6.976),\n",
       " (12, 8.01),\n",
       " (12, 9.93),\n",
       " (12, 10.45),\n",
       " (12, 9.68),\n",
       " (5, 6.871),\n",
       " (12, 10.15),\n",
       " (5, 6.86),\n",
       " (5, 6.816),\n",
       " (12, 9.64),\n",
       " (5, 6.812),\n",
       " (12, 7.79),\n",
       " (5, 6.861),\n",
       " (5, 6.871),\n",
       " (5, 6.939)]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list2\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dbe6e84d-6a91-4bb3-a26d-5b7f85efbd9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 506 but corresponding boolean dimension is 14",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [66]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mXy\u001b[49m\u001b[43m[\u001b[49m\u001b[43mXy\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m[:,:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],Xy[Xy[col]\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m10\u001b[39m][:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 506 but corresponding boolean dimension is 14"
     ]
    }
   ],
   "source": [
    "Xy[Xy[2]<10][:,:-1],Xy[Xy[col]<10][:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7e9d390e-bb88-4dbf-8a8a-69b535571ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 14)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(Xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a0e81d6d-18a7-4307-8a6c-10aa57e49f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270, 13)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(Xy[Xy[:,2]<10][:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0b72793a-8a0b-4826-9c14-b16ea34d90de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "         4.9800e+00],\n",
       "        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "         9.1400e+00],\n",
       "        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "         4.0300e+00],\n",
       "        ...,\n",
       "        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         5.6400e+00],\n",
       "        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "         6.4800e+00],\n",
       "        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         7.8800e+00]]),\n",
       " array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xy[Xy[:,col]<split][:,:-1],Xy[Xy[:,col]<split][:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "be021f36-5ba5-4a27-abd2-dd6e44f4bc31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270,)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(Xy[Xy[:,2]<10][:,-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "59668f42-10ba-4941-b0f5-97a2a8f6cb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston, load_iris, load_wine, load_breast_cancer, fetch_california_housing\n",
    "X, y = load_boston(return_X_y=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2080f357-6f65-4959-9a1b-faa6dd8053a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12.0, 9.88)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_best_split(X,y,np.var,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1dceddfe-10ae-4045-8826-de160705748a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506,)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X[:,0])   #Column 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "91a58f96-71fa-487e-a852-a52a197253d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506,)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3032fe4d-2d72-45a2-9b41-7b192d671cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.32000e-03, 1.80000e+01, 2.31000e+00, ..., 3.96900e+02,\n",
       "        4.98000e+00, 2.40000e+01],\n",
       "       [9.06000e-03, 9.00000e+01, 2.97000e+00, ..., 3.94720e+02,\n",
       "        7.85000e+00, 3.22000e+01],\n",
       "       [1.09600e-02, 5.50000e+01, 2.25000e+00, ..., 3.94720e+02,\n",
       "        8.23000e+00, 2.20000e+01],\n",
       "       ...,\n",
       "       [6.79208e+01, 0.00000e+00, 1.81000e+01, ..., 3.84970e+02,\n",
       "        2.29800e+01, 5.00000e+00],\n",
       "       [7.35341e+01, 0.00000e+00, 1.81000e+01, ..., 1.64500e+01,\n",
       "        2.06200e+01, 8.80000e+00],\n",
       "       [8.89762e+01, 0.00000e+00, 1.81000e+01, ..., 3.96900e+02,\n",
       "        1.72100e+01, 1.04000e+01]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test=X[:,1]\n",
    "\n",
    "y_reshape=np.reshape(y,(np.shape(y)[0],1))\n",
    "Xy=np.hstack((X,y_reshape))\n",
    "\n",
    "Xy[:,[0,-1]][:,-1]==y\n",
    "\n",
    "#define new matrix with rows sorted in ascending order by values in second column\n",
    "x_sorted_asc = Xy[Xy[:, 0].argsort()]\n",
    "x_sorted_asc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5c2155dc-e7e4-485f-bee5-301ca354cb94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.97"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(X[:,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05398bc4-e7f5-4309-b698-2c2c00514f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(np.shape(X)[1]):\n",
    "    print(X[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734e97e4-7b46-4491-84e5-3db004570b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a5987333-dbcd-4e44-9359-2cdc2e0960cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9d881ce6-2edd-4fa3-869d-3b2b5c279de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(X, y,loss, min_samples_leaf):\n",
    "    y_reshape=np.reshape(y,(np.shape(y)[0],1)) #reshaping so that dimensions align\n",
    "    Xy=np.hstack((X,y_reshape))                #stacking X along with y\n",
    "    loss_list=[]\n",
    "    split_indices=np.random.choice(np.shape(X)[0], size = 11, replace = False, p = None)\n",
    "    feature=-1\n",
    "    split=-1\n",
    "    best_loss=loss(y)\n",
    "        \n",
    "    if loss==np.var:\n",
    "        \n",
    "        for i in range(np.shape(X)[1]):\n",
    "            loss_list_temp=[]\n",
    "            Xy_t=Xy[:,[i,-1]]                      #stacking columns of X with y, turn by turn\n",
    "            x_sorted_asc = Xy_t[Xy_t[:, 0].argsort()] #sorting on first column\n",
    "            #for j in range(np.shape(x_sorted_asc[0])):\n",
    "            #print(x_sorted_asc)\n",
    "            #print(np.shape(x_sorted_asc)) \n",
    "            for j in split_indices:\n",
    "                \n",
    "                if np.shape(x_sorted_asc[:j,1])[0]<min_samples_leaf:\n",
    "                    continue\n",
    "                        \n",
    "                else:\n",
    "                    err1=np.var(x_sorted_asc[:j,1])\n",
    "                    err2=np.var(x_sorted_asc[j:,1])\n",
    "                    len1=np.shape(x_sorted_asc[:j,1])[0]\n",
    "                    len2=np.shape(x_sorted_asc[j:,1])[0]\n",
    "            \n",
    "\n",
    "            \n",
    "                    loss=(len1*err1 + len2*err2)/(len1+len2)\n",
    "                    if loss==0:\n",
    "                        return i,j\n",
    "                        break\n",
    "                        \n",
    "                    else:    \n",
    "                        loss_list_temp.append((loss,i,j))\n",
    "        \n",
    "            loss_list.append(loss_list_temp)\n",
    "        \n",
    "        arr=np.array(loss_list)\n",
    "        m=np.min(arr[:,:,0])  #Min loss \n",
    "        #best_split=(arr[arr[:,:,0]==m][0],arr[arr[:,:,0]==m][1])\n",
    "        if m<best_loss:\n",
    "            \n",
    "            best_split =arr[arr[:,:,0]==m] \n",
    "            feature=best_split[0][1]\n",
    "            split=best_split[0][2]\n",
    "            best_loss=best_split[0][0]\n",
    "        \n",
    "            \n",
    "        return feature,split\n",
    "    \n",
    "    else:\n",
    "        \n",
    "            for i in range(np.shape(X)[1]):\n",
    "                loss_list_temp=[]\n",
    "                Xy_t=Xy[:,[i,-1]]                      #stacking columns of X with y, turn by turn\n",
    "                x_sorted_asc = Xy_t[Xy_t[:, 0].argsort()] #sorting on first column\n",
    "                #for j in range(np.shape(x_sorted_asc[0])):\n",
    "                #print(x_sorted_asc)\n",
    "                #print(np.shape(x_sorted_asc)) \n",
    "                for j in split_indices:\n",
    "                \n",
    "                    if np.shape(x_sorted_asc[:j,1])[0]<min_samples_leaf:\n",
    "                        continue\n",
    "                        \n",
    "                    else:\n",
    "                        err1=np.var(x_sorted_asc[:j,1])\n",
    "                        err2=np.var(x_sorted_asc[j:,1])\n",
    "                        len1=np.shape(x_sorted_asc[:j,1])[0]\n",
    "                        len2=np.shape(x_sorted_asc[j:,1])[0]\n",
    "            \n",
    "\n",
    "            \n",
    "                        loss=(len1*err1 + len2*err2)/(len1+len2)\n",
    "                        if loss==0:\n",
    "                            return i,j\n",
    "                            break\n",
    "                        \n",
    "                        else:    \n",
    "                            loss_list_temp.append((loss,i,j))\n",
    "        \n",
    "            loss_list.append(loss_list_temp)\n",
    "        \n",
    "            arr=np.array(loss_list)\n",
    "            m=np.min(arr[:,:,0])  #Min loss \n",
    "            #best_split=(arr[arr[:,:,0]==m][0],arr[arr[:,:,0]==m][1])\n",
    "            if m<best_loss:\n",
    "            \n",
    "                best_split =arr[arr[:,:,0]==m] \n",
    "                feature=best_split[0][1]\n",
    "                split=best_split[0][2]\n",
    "                best_loss=best_split[0][0]\n",
    "        \n",
    "            \n",
    "            return feature,split\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "                \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "bf5e3d1b-b474-4a77-838d-9f727f140ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1, -1)"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_best_split(X,y,gini,10)\n",
    "#m=np.min(arr[:,:,0])\n",
    "#arr[arr[:,:,0]==m]\n",
    " #Xy_t[Xy_t[:, 0].argsort()]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "e24db8bf-65c4-449c-ad94-e5b670eeae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "lis=[13,54,546,2,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "74552f3a-b28e-4148-b7bc-d3b64cf19b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "82ff7694-78b9-4ad2-a0ca-6e2d867ca7f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'lchild' and 'rchild'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [234]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mDecisionNode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'lchild' and 'rchild'"
     ]
    }
   ],
   "source": [
    "DecisionNode(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "282215a5-7506-4796-a21d-ea9776b8be69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 6, 5])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice( [1,2,3,5,6,7] , size = 3, replace = False, p = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68e500a7-a935-4f6e-bf27-7abe92b488de",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_wine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mload_wine\u001b[49m(return_X_y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_wine' is not defined"
     ]
    }
   ],
   "source": [
    "X, y = load_wine(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "e4a0685a-7753-4f2d-8ee1-19b16b3f1320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.0, 64.0)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_best_split(X,y,np.var,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "7ff01fa3-30b8-4c5b-8e97-c6257b68bd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree=DecisionTree621"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "12cb2224-5521-4244-ae17-08eacbaff7aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [402]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: fit() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "tree.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d36cb7-ed98-46a4-bc0c-291f4ab10627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4dc37b2-e954-47ac-9321-e34434a643df",
   "metadata": {},
   "outputs": [],
   "source": [
    " X, y = load_boston(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a38c371-0c0e-4285-9646-2cd3e1d6fffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "26b0c19d-3e4b-4003-8ae4-3595304ff88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "col,split=find_best_split(X, y,np.var, 1)\n",
    "col=int(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ecebbb1-790b-41eb-bff9-b85cad304354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "         4.9800e+00],\n",
       "        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "         9.1400e+00],\n",
       "        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "         4.0300e+00],\n",
       "        ...,\n",
       "        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         5.6400e+00],\n",
       "        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "         6.4800e+00],\n",
       "        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         7.8800e+00]]),\n",
       " array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xy[Xy[:,col]<split][:,:-1],Xy[Xy[:,col]<split][:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a8d460-79c2-4295-9b21-838c0ecb7dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
