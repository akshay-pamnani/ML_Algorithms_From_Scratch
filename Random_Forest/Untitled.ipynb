{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1df58687-312d-487b-97db-12439bdf1df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "oob_index_values={key:[] for key in range(10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2552f872-e505-48ad-80e3-c1daa4b0fcf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [], 1: [], 2: [], 3: [], 4: [], 5: [], 6: [], 7: [], 8: [], 9: []}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oob_index_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6fef4342-df4a-480c-998c-5cc8169e5db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.9.12, pytest-7.1.1, pluggy-1.0.0\n",
      "rootdir: /Users/akshaypamnani/Desktop/USF-MSDS 2022_Academics/Machine Learning/ML_HW4\n",
      "plugins: anyio-3.5.0\n",
      "collected 26 items                                                             \u001b[0m\u001b[1m\n",
      "\n",
      "test_rf.py \u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31m                                    [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m_______________________________ test_boston_oob ________________________________\u001b[0m\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_boston_oob\u001b[39;49;00m():\n",
      "        X, y = load_boston(return_X_y=\u001b[94mTrue\u001b[39;49;00m)\n",
      ">       run_regression_test(X, y, min_training_score = \u001b[94m.86\u001b[39;49;00m, oob=\u001b[94mTrue\u001b[39;49;00m)\n",
      "\n",
      "\u001b[1m\u001b[31mtest_rf.py\u001b[0m:18: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "X = array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
      "        4.9800e+00],\n",
      "       [2.7310e-02, 0.00...02,\n",
      "        1.2920e+01],\n",
      "       [1.7783e-01, 0.0000e+00, 9.6900e+00, ..., 1.9200e+01, 3.9577e+02,\n",
      "        1.5100e+01]])\n",
      "y = array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
      "       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17... , 21.8,\n",
      "       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
      "       23.1, 19.7, 18.3, 21.2, 17.5])\n",
      "ntrials = 2, min_training_score = 0.86, min_samples_leaf = 3, max_features = 0.3\n",
      "grace = 0.08, oob = True, n_estimators = 18\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mrun_regression_test\u001b[39;49;00m(X, y, ntrials=\u001b[94m2\u001b[39;49;00m, min_training_score = \u001b[94m.85\u001b[39;49;00m, min_samples_leaf=\u001b[94m3\u001b[39;49;00m, max_features=\u001b[94m0.3\u001b[39;49;00m, grace=\u001b[94m.08\u001b[39;49;00m, oob=\u001b[94mFalse\u001b[39;49;00m, n_estimators=\u001b[94m18\u001b[39;49;00m):\n",
      "        stack = inspect.stack()\n",
      "        caller_name = stack[\u001b[94m1\u001b[39;49;00m].function[\u001b[96mlen\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mtest_\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m):]\n",
      "        X = X[:\u001b[94m500\u001b[39;49;00m]\n",
      "        y = y[:\u001b[94m500\u001b[39;49;00m]\n",
      "    \n",
      "        test_scores = []\n",
      "        train_scores = []\n",
      "        oob_scores = []\n",
      "    \n",
      "        sklearn_scores = []\n",
      "        sklearn_train_scores = []\n",
      "        sklearn_oob_scores = []\n",
      "    \n",
      "        \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(ntrials):\n",
      "            X_train, X_test, y_train, y_test = \\\n",
      "                train_test_split(X, y, test_size=\u001b[94m0.20\u001b[39;49;00m)\n",
      "    \n",
      "            rf = RandomForestRegressor621(n_estimators=n_estimators, min_samples_leaf=min_samples_leaf, max_features=max_features, oob_score=oob)\n",
      "            rf.fit(X_train, y_train)\n",
      "            train_scores.append(rf.score(X_train, y_train))\n",
      "            test_scores.append(rf.score(X_test, y_test))\n",
      "            oob_scores.append(rf.oob_score_)\n",
      "    \n",
      "            sklearn_rf = RandomForestRegressor(n_estimators=n_estimators, min_samples_leaf=min_samples_leaf, max_features=max_features, oob_score=oob)\n",
      "            sklearn_rf.fit(X_train, y_train)\n",
      "            sklearn_train_scores.append(sklearn_rf.score(X_train, y_train))\n",
      "            sklearn_scores.append(sklearn_rf.score(X_test, y_test))\n",
      "            \u001b[94mif\u001b[39;49;00m oob:\n",
      "                sklearn_oob_scores.append(sklearn_rf.oob_score_)\n",
      "            \u001b[94melse\u001b[39;49;00m:\n",
      "                sklearn_oob_scores.append(\u001b[94m0.0\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[96mprint\u001b[39;49;00m()\n",
      "        \u001b[94mif\u001b[39;49;00m oob:\n",
      "            \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcaller_name\u001b[33m}\u001b[39;49;00m\u001b[33m: 621 OOB score \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnp.mean(oob_scores)\u001b[33m:\u001b[39;49;00m\u001b[33m.2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m vs sklearn OOB \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnp.mean(sklearn_oob_scores)\u001b[33m:\u001b[39;49;00m\u001b[33m.2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcaller_name\u001b[33m}\u001b[39;49;00m\u001b[33m: 621     Train R^2 score mean \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnp.mean(train_scores)\u001b[33m:\u001b[39;49;00m\u001b[33m.2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m, stddev \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnp.std(train_scores)\u001b[33m:\u001b[39;49;00m\u001b[33m3f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcaller_name\u001b[33m}\u001b[39;49;00m\u001b[33m: Sklearn Train R^2 score mean \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnp.mean(sklearn_train_scores)\u001b[33m:\u001b[39;49;00m\u001b[33m.2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m, stddev \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnp.std(sklearn_train_scores)\u001b[33m:\u001b[39;49;00m\u001b[33m3f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcaller_name\u001b[33m}\u001b[39;49;00m\u001b[33m: 621     Test  R^2 score mean \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnp.mean(test_scores)\u001b[33m:\u001b[39;49;00m\u001b[33m.2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m, stddev \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnp.std(test_scores)\u001b[33m:\u001b[39;49;00m\u001b[33m3f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcaller_name\u001b[33m}\u001b[39;49;00m\u001b[33m: Sklearn Test  R^2 score mean \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnp.mean(sklearn_scores)\u001b[33m:\u001b[39;49;00m\u001b[33m.2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m, stddev \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnp.std(sklearn_scores)\u001b[33m:\u001b[39;49;00m\u001b[33m3f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94massert\u001b[39;49;00m np.mean(train_scores) >= min_training_score, \\\n",
      "               \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mTraining R^2: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnp.mean(train_scores)\u001b[33m:\u001b[39;49;00m\u001b[33m.2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m must be >= \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mmin_training_score\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m np.mean(test_scores)+grace >= np.mean(sklearn_scores), \\\n",
      "               \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mTesting R^2: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnp.mean(test_scores)\u001b[33m:\u001b[39;49;00m\u001b[33m.2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m must be within \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mgrace\u001b[33m:\u001b[39;49;00m\u001b[33m.2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m of sklearn score: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnp.mean(sklearn_scores)\u001b[33m:\u001b[39;49;00m\u001b[33m.2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m oob:\n",
      ">           \u001b[94massert\u001b[39;49;00m np.abs(np.mean(oob_scores) - np.mean(sklearn_oob_scores)) < grace, \\\n",
      "                \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOOB R^2: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnp.mean(oob_scores)\u001b[33m:\u001b[39;49;00m\u001b[33m.2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m must be within \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mgrace\u001b[33m:\u001b[39;49;00m\u001b[33m2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m of sklearn score: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnp.mean(sklearn_oob_scores)\u001b[33m:\u001b[39;49;00m\u001b[33m.2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AssertionError: OOB R^2: -0.09 must be within 0.080000 of sklearn score: 0.82\u001b[0m\n",
      "\u001b[1m\u001b[31mE           assert 0.908751020127297 < 0.08\u001b[0m\n",
      "\u001b[1m\u001b[31mE            +  where 0.908751020127297 = <ufunc 'absolute'>((-0.09216840727066966 - 0.8165826128566274))\u001b[0m\n",
      "\u001b[1m\u001b[31mE            +    where <ufunc 'absolute'> = np.abs\u001b[0m\n",
      "\u001b[1m\u001b[31mE            +    and   -0.09216840727066966 = <function mean at 0x7f9650a73e50>([-0.13048129822423205, -0.05385551631710728])\u001b[0m\n",
      "\u001b[1m\u001b[31mE            +      where <function mean at 0x7f9650a73e50> = np.mean\u001b[0m\n",
      "\u001b[1m\u001b[31mE            +    and   0.8165826128566274 = <function mean at 0x7f9650a73e50>([0.8370549615655027, 0.7961102641477519])\u001b[0m\n",
      "\u001b[1m\u001b[31mE            +      where <function mean at 0x7f9650a73e50> = np.mean\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_rf.py\u001b[0m:164: AssertionError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "\n",
      "boston_oob: 621 OOB score -0.09 vs sklearn OOB 0.82\n",
      "boston_oob: 621     Train R^2 score mean 0.87, stddev 0.045522\n",
      "boston_oob: Sklearn Train R^2 score mean 0.93, stddev 0.002388\n",
      "boston_oob: 621     Test  R^2 score mean 0.81, stddev 0.064590\n",
      "boston_oob: Sklearn Test  R^2 score mean 0.81, stddev 0.072631\n",
      "\u001b[31m\u001b[1m_______________________ test_boston_min_samples_leaf_oob _______________________\u001b[0m\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_boston_min_samples_leaf_oob\u001b[39;49;00m():\n",
      "        X, y = load_boston(return_X_y=\u001b[94mTrue\u001b[39;49;00m)\n",
      ">       run_regression_test(X, y, ntrials=\u001b[94m5\u001b[39;49;00m, min_samples_leaf=\u001b[94m5\u001b[39;49;00m, grace=\u001b[94m0.08\u001b[39;49;00m, oob=\u001b[94mTrue\u001b[39;49;00m)\n",
      "\n",
      "\u001b[1m\u001b[31mtest_rf.py\u001b[0m:34: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "X = array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
      "        4.9800e+00],\n",
      "       [2.7310e-02, 0.00...02,\n",
      "        1.2920e+01],\n",
      "       [1.7783e-01, 0.0000e+00, 9.6900e+00, ..., 1.9200e+01, 3.9577e+02,\n",
      "        1.5100e+01]])\n",
      "y = array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
      "       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17... , 21.8,\n",
      "       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
      "       23.1, 19.7, 18.3, 21.2, 17.5])\n",
      "ntrials = 5, min_training_score = 0.85, min_samples_leaf = 5, max_features = 0.3\n",
      "grace = 0.08, oob = True, n_estimators = 18\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mrun_regression_test\u001b[39;49;00m(X, y, ntrials=\u001b[94m2\u001b[39;49;00m, min_training_score = \u001b[94m.85\u001b[39;49;00m, min_samples_leaf=\u001b[94m3\u001b[39;49;00m, max_features=\u001b[94m0.3\u001b[39;49;00m, grace=\u001b[94m.08\u001b[39;49;00m, oob=\u001b[94mFalse\u001b[39;49;00m, n_estimators=\u001b[94m18\u001b[39;49;00m):\n",
      "        stack = inspect.stack()\n",
      "        caller_name = stack[\u001b[94m1\u001b[39;49;00m].function[\u001b[96mlen\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mtest_\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m):]\n",
      "        X = X[:\u001b[94m500\u001b[39;49;00m]\n",
      "        y = y[:\u001b[94m500\u001b[39;49;00m]\n",
      "    \n",
      "        test_scores = []\n",
      "        train_scores = []\n",
      "        oob_scores = []\n",
      "    \n",
      "        sklearn_scores = []\n",
      "        sklearn_train_scores = []\n",
      "        sklearn_oob_scores = []\n",
      "    \n",
      "        \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(ntrials):\n",
      "            X_train, X_test, y_train, y_test = \\\n",
      "                train_test_split(X, y, test_size=\u001b[94m0.20\u001b[39;49;00m)\n",
      "    \n",
      "            rf = RandomForestRegressor621(n_estimators=n_estimators, min_samples_leaf=min_samples_leaf, max_features=max_features, oob_score=oob)\n",
      "            rf.fit(X_train, y_train)\n",
      "            train_scores.append(rf.score(X_train, y_train))\n",
      "            test_scores.append(rf.score(X_test, y_test))\n",
      "            oob_scores.append(rf.oob_score_)\n",
      "    \n",
      "            sklearn_rf = RandomForestRegressor(n_estimators=n_estimators, min_samples_leaf=min_samples_leaf, max_features=max_features, oob_score=oob)\n",
      "            sklearn_rf.fit(X_train, y_train)\n",
      "            sklearn_train_scores.append(sklearn_rf.score(X_train, y_train))\n",
      "            sklearn_scores.append(sklearn_rf.score(X_test, y_test))\n",
      "            \u001b[94mif\u001b[39;49;00m oob:\n",
      "                sklearn_oob_scores.append(sklearn_rf.oob_score_)\n",
      "            \u001b[94melse\u001b[39;49;00m:\n",
      "                sklearn_oob_scores.append(\u001b[94m0.0\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[96mprint\u001b[39;49;00m()\n",
      "        \u001b[94mif\u001b[39;49;00m oob:\n",
      "            \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcaller_name\u001b[33m}\u001b[39;49;00m\u001b[33m: 621 OOB score \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnp.mean(oob_scores)\u001b[33m:\u001b[39;49;00m\u001b[33m.2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m vs sklearn OOB \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnp.mean(sklearn_oob_scores)\u001b[33m:\u001b[39;49;00m\u001b[33m.2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcaller_name\u001b[33m}\u001b[39;49;00m\u001b[33m: 621     Train R^2 score mean \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnp.mean(train_scores)\u001b[33m:\u001b[39;49;00m\u001b[33m.2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m, stddev \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnp.std(train_scores)\u001b[33m:\u001b[39;49;00m\u001b[33m3f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcaller_name\u001b[33m}\u001b[39;49;00m\u001b[33m: Sklearn Train R^2 score mean \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnp.mean(sklearn_train_scores)\u001b[33m:\u001b[39;49;00m\u001b[33m.2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m, stddev \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnp.std(sklearn_train_scores)\u001b[33m:\u001b[39;49;00m\u001b[33m3f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcaller_name\u001b[33m}\u001b[39;49;00m\u001b[33m: 621     Test  R^2 score mean \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnp.mean(test_scores)\u001b[33m:\u001b[39;49;00m\u001b[33m.2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m, stddev \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnp.std(test_scores)\u001b[33m:\u001b[39;49;00m\u001b[33m3f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcaller_name\u001b[33m}\u001b[39;49;00m\u001b[33m: Sklearn Test  R^2 score mean \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnp.mean(sklearn_scores)\u001b[33m:\u001b[39;49;00m\u001b[33m.2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m, stddev \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnp.std(sklearn_scores)\u001b[33m:\u001b[39;49;00m\u001b[33m3f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94massert\u001b[39;49;00m np.mean(train_scores) >= min_training_score, \\\n",
      "               \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mTraining R^2: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnp.mean(train_scores)\u001b[33m:\u001b[39;49;00m\u001b[33m.2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m must be >= \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mmin_training_score\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m np.mean(test_scores)+grace >= np.mean(sklearn_scores), \\\n",
      "               \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mTesting R^2: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnp.mean(test_scores)\u001b[33m:\u001b[39;49;00m\u001b[33m.2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m must be within \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mgrace\u001b[33m:\u001b[39;49;00m\u001b[33m.2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m of sklearn score: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnp.mean(sklearn_scores)\u001b[33m:\u001b[39;49;00m\u001b[33m.2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m oob:\n",
      ">           \u001b[94massert\u001b[39;49;00m np.abs(np.mean(oob_scores) - np.mean(sklearn_oob_scores)) < grace, \\\n",
      "                \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOOB R^2: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnp.mean(oob_scores)\u001b[33m:\u001b[39;49;00m\u001b[33m.2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m must be within \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mgrace\u001b[33m:\u001b[39;49;00m\u001b[33m2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m of sklearn score: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnp.mean(sklearn_oob_scores)\u001b[33m:\u001b[39;49;00m\u001b[33m.2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AssertionError: OOB R^2: 0.64 must be within 0.080000 of sklearn score: 0.77\u001b[0m\n",
      "\u001b[1m\u001b[31mE           assert 0.1274501731519614 < 0.08\u001b[0m\n",
      "\u001b[1m\u001b[31mE            +  where 0.1274501731519614 = <ufunc 'absolute'>((0.6448310745905141 - 0.7722812477424755))\u001b[0m\n",
      "\u001b[1m\u001b[31mE            +    where <ufunc 'absolute'> = np.abs\u001b[0m\n",
      "\u001b[1m\u001b[31mE            +    and   0.6448310745905141 = <function mean at 0x7f9650a73e50>([0.7834293265384165, 0.80427633956808, 0.7960592869893842, 0.0229317986927432, 0.8174586211639465])\u001b[0m\n",
      "\u001b[1m\u001b[31mE            +      where <function mean at 0x7f9650a73e50> = np.mean\u001b[0m\n",
      "\u001b[1m\u001b[31mE            +    and   0.7722812477424755 = <function mean at 0x7f9650a73e50>([0.7517051352658147, 0.8025276137661729, 0.7190814992124721, 0.788402598036046, 0.799689392431872])\u001b[0m\n",
      "\u001b[1m\u001b[31mE            +      where <function mean at 0x7f9650a73e50> = np.mean\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_rf.py\u001b[0m:164: AssertionError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "\n",
      "boston_min_samples_leaf_oob: 621 OOB score 0.64 vs sklearn OOB 0.77\n",
      "boston_min_samples_leaf_oob: 621     Train R^2 score mean 0.88, stddev 0.017138\n",
      "boston_min_samples_leaf_oob: Sklearn Train R^2 score mean 0.89, stddev 0.008321\n",
      "boston_min_samples_leaf_oob: 621     Test  R^2 score mean 0.80, stddev 0.033687\n",
      "boston_min_samples_leaf_oob: Sklearn Test  R^2 score mean 0.82, stddev 0.025824\n",
      "\u001b[31m\u001b[1m________________________________ test_iris_oob _________________________________\u001b[0m\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_iris_oob\u001b[39;49;00m():\n",
      "        X, y = load_iris(return_X_y=\u001b[94mTrue\u001b[39;49;00m)\n",
      ">       run_classification_test(X, y, ntrials=\u001b[94m5\u001b[39;49;00m, min_training_score=\u001b[94m0.93\u001b[39;49;00m, oob=\u001b[94mTrue\u001b[39;49;00m)\n",
      "\n",
      "\u001b[1m\u001b[31mtest_rf.py\u001b[0m:83: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "X = array([[5.1, 3.5, 1.4, 0.2],\n",
      "       [4.9, 3. , 1.4, 0.2],\n",
      "       [4.7, 3.2, 1.3, 0.2],\n",
      "       [4.6, 3.1, 1.5, 0.2],\n",
      "  ...],\n",
      "       [6.3, 2.5, 5. , 1.9],\n",
      "       [6.5, 3. , 5.2, 2. ],\n",
      "       [6.2, 3.4, 5.4, 2.3],\n",
      "       [5.9, 3. , 5.1, 1.8]])\n",
      "y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "ntrials = 5, min_samples_leaf = 3, max_features = 0.3, min_training_score = 0.93\n",
      "grace = 0.07, oob = True, n_estimators = 15\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mrun_classification_test\u001b[39;49;00m(X, y, ntrials=\u001b[94m1\u001b[39;49;00m, min_samples_leaf=\u001b[94m3\u001b[39;49;00m, max_features=\u001b[94m0.3\u001b[39;49;00m, min_training_score=\u001b[94m1.0\u001b[39;49;00m, grace=\u001b[94m.07\u001b[39;49;00m, oob=\u001b[94mFalse\u001b[39;49;00m, n_estimators=\u001b[94m15\u001b[39;49;00m):\n",
      "        stack = inspect.stack()\n",
      "        caller_name = stack[\u001b[94m1\u001b[39;49;00m].function[\u001b[96mlen\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mtest_\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m):]\n",
      "        X = X[:\u001b[94m500\u001b[39;49;00m]\n",
      "        y = y[:\u001b[94m500\u001b[39;49;00m]\n",
      "    \n",
      "        test_scores = []\n",
      "        train_scores = []\n",
      "        oob_scores = []\n",
      "    \n",
      "        sklearn_test_scores = []\n",
      "        sklearn_train_scores = []\n",
      "        sklearn_oob_scores = []\n",
      "    \n",
      "        \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(ntrials):\n",
      "            X_train, X_test, y_train, y_test = \\\n",
      "                train_test_split(X, y, test_size=\u001b[94m0.20\u001b[39;49;00m)\n",
      "    \n",
      "            rf = RandomForestClassifier621(n_estimators=n_estimators, min_samples_leaf=min_samples_leaf, max_features=max_features, oob_score=oob)\n",
      "            rf.fit(X_train, y_train)\n",
      "            train_scores.append(rf.score(X_train, y_train))\n",
      "            test_scores.append(rf.score(X_test, y_test))\n",
      "            oob_scores.append(rf.oob_score_)\n",
      "    \n",
      "            sklearn_rf = RandomForestClassifier(n_estimators=n_estimators, min_samples_leaf=min_samples_leaf, max_features=max_features, oob_score=oob)\n",
      "            sklearn_rf.fit(X_train, y_train)\n",
      "            sklearn_train_scores.append(sklearn_rf.score(X_train, y_train))\n",
      "            sklearn_test_scores.append(sklearn_rf.score(X_test, y_test))\n",
      "            \u001b[94mif\u001b[39;49;00m oob:\n",
      "                sklearn_oob_scores.append(sklearn_rf.oob_score_)\n",
      "            \u001b[94melse\u001b[39;49;00m:\n",
      "                sklearn_oob_scores.append(\u001b[94m0.0\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[94mif\u001b[39;49;00m oob:\n",
      ">           \u001b[94massert\u001b[39;49;00m np.abs(np.mean(oob_scores) - np.mean(sklearn_oob_scores)) < grace, \\\n",
      "                   \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOOB accuracy: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnp.mean(oob_scores)\u001b[33m:\u001b[39;49;00m\u001b[33m.2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m must be within \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mgrace\u001b[33m:\u001b[39;49;00m\u001b[33m.2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m of sklearn score: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnp.mean(sklearn_oob_scores)\u001b[33m:\u001b[39;49;00m\u001b[33m.2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AssertionError: OOB accuracy: 0.75 must be within 0.07 of sklearn score: 0.93\u001b[0m\n",
      "\u001b[1m\u001b[31mE           assert 0.18754878222475424 < 0.07\u001b[0m\n",
      "\u001b[1m\u001b[31mE            +  where 0.18754878222475424 = <ufunc 'absolute'>((0.7474512177752457 - 0.9349999999999999))\u001b[0m\n",
      "\u001b[1m\u001b[31mE            +    where <ufunc 'absolute'> = np.abs\u001b[0m\n",
      "\u001b[1m\u001b[31mE            +    and   0.7474512177752457 = <function mean at 0x7f9650a73e50>([0.9333333333333333, 0.9333333333333333, 0.5084745762711864, 0.9083333333333333, 0.453781512605042])\u001b[0m\n",
      "\u001b[1m\u001b[31mE            +      where <function mean at 0x7f9650a73e50> = np.mean\u001b[0m\n",
      "\u001b[1m\u001b[31mE            +    and   0.9349999999999999 = <function mean at 0x7f9650a73e50>([0.9416666666666667, 0.9333333333333333, 0.9583333333333334, 0.9166666666666666, 0.925])\u001b[0m\n",
      "\u001b[1m\u001b[31mE            +      where <function mean at 0x7f9650a73e50> = np.mean\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_rf.py\u001b[0m:202: AssertionError\n",
      "\u001b[33m=============================== warnings summary ===============================\u001b[0m\n",
      "test_rf.py: 156 warnings\n",
      "  /Users/akshaypamnani/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "    return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "\n",
      "test_rf.py: 156 warnings\n",
      "  /Users/akshaypamnani/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "    ret = ret.dtype.type(ret / rcount)\n",
      "\n",
      "test_rf.py::test_boston_min_samples_leaf_oob\n",
      "test_rf.py::test_boston_min_samples_leaf_oob\n",
      "test_rf.py::test_boston_min_samples_leaf_oob\n",
      "  /Users/akshaypamnani/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:833: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "    warn(\"Some inputs do not have OOB scores. \"\n",
      "\n",
      "test_rf.py::test_wine_oob\n",
      "test_rf.py::test_wine_min_samples_leaf_oob\n",
      "  /Users/akshaypamnani/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:541: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "    warn(\"Some inputs do not have OOB scores. \"\n",
      "\n",
      "test_rf.py::test_wine_oob\n",
      "test_rf.py::test_wine_min_samples_leaf_oob\n",
      "  /Users/akshaypamnani/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:545: RuntimeWarning: invalid value encountered in true_divide\n",
      "    decision = (predictions[k] /\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "=========================== short test summary info ============================\n",
      "FAILED test_rf.py::test_boston_oob - AssertionError: OOB R^2: -0.09 must be w...\n",
      "FAILED test_rf.py::test_boston_min_samples_leaf_oob - AssertionError: OOB R^2...\n",
      "FAILED test_rf.py::test_iris_oob - AssertionError: OOB accuracy: 0.75 must be...\n",
      "\u001b[31m============ \u001b[31m\u001b[1m3 failed\u001b[0m, \u001b[32m23 passed\u001b[0m, \u001b[33m319 warnings\u001b[0m\u001b[31m in 115.19s (0:01:55)\u001b[0m\u001b[31m ============\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf938df4-3087-4a3f-b8ad-ebe58c99f1f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
