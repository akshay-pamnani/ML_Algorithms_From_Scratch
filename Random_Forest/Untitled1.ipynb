{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97c5007d-035b-41ae-b2c9-49ccba4e2e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from dtree import *\n",
    "\n",
    "class RandomForest621:\n",
    "    def __init__(self, n_estimators=10, oob_score=False,min_samples_leaf=3,max_features=0.3):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.oob_score = oob_score\n",
    "        self.oob_score_ = np.nan\n",
    "        self.min_samples_leaf=min_samples_leaf\n",
    "        self.max_features=max_features\n",
    "        self.trees=[]\n",
    "\n",
    "    def compute_oob_score(self,X,y):\n",
    "\n",
    "        oob_index_values={key:[] for key in range(len(X))}\n",
    "        oob_index_preds={}\n",
    "\n",
    "        for tree in self.trees:\n",
    "            \n",
    "            if isinstance(self, RandomForestRegressor621):\n",
    "\n",
    "                oob_predictions_leaves=tree.predict(X[tree.oob_index])\n",
    "                oob_predictions=[leaf.prediction for leaf in oob_predictions_leaves]\n",
    "\n",
    "            for i in range(len(oob_predictions)):\n",
    "                \n",
    "                index=tree.oob_index[i]\n",
    "\n",
    "                oob_index_values[index].append(oob_predictions[i])\n",
    "\n",
    "        #loss = self.trees[0].loss\n",
    "        #loss(y)\n",
    "        for i in range(len(X)):\n",
    "            oob_index_preds[i]=np.mean(oob_index_values[i])\n",
    "\n",
    "            #Have to deal with missing values\n",
    "            \n",
    "        oob_predictions=list(oob_index_preds.values())\n",
    "        oob_predictions=oob_predictions[np.where(~np.isnan(oob_predictions))]\n",
    "        y_filtered=y[np.where(~np.isnan(oob_predictions))]\n",
    "\n",
    "\n",
    "        return self.trees[0].score(oob_predictions,y_filtered)\n",
    "   \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Given an (X, y) training set, fit all n_estimators trees to different,\n",
    "        bootstrapped versions of the training data.  Keep track of the indexes of\n",
    "        the OOB records for each tree.  After fitting all of the trees in the forest,\n",
    "        compute the OOB validation score estimate and store as self.oob_score_, to\n",
    "        mimic sklearn.\n",
    "        \"\"\"\n",
    "\n",
    "        oob_index_dict={}\n",
    "        trees_dict={}\n",
    "\n",
    "        for i in range(self.n_estimators):\n",
    "            n = len(y)\n",
    "            idx = np.random.randint(0, n, size = n)\n",
    "            X_train = X[idx]\n",
    "            y_train = y[idx]\n",
    "            oob_index=np.array([i for i in range(len(X)) if i not in idx])\n",
    "            #oob_index_dict[i]=oob_index\n",
    "            if isinstance(self, RandomForestRegressor621):\n",
    "                tree=RegressionTree621(self.min_samples_leaf, self.max_features, oob_index)\n",
    "                tree.fit(X_train,y_train)\n",
    "            #trees_dict[i]=tree\n",
    "                self.trees.append(tree)\n",
    "                self.oob_score_=self.compute_oob_score(X,y)\n",
    "\n",
    "            elif isinstance(self, RandomForestClassifier621):\n",
    "                tree=ClassifierTree621(self.min_samples_leaf, self.max_features, oob_index)\n",
    "                tree.fit(X_train,y_train)\n",
    "                self.trees.append(tree)\n",
    "                #self.oob_score_=self.compute_oob_score(self,X,y)\n",
    "\n",
    "class RandomForestRegressor621(RandomForest621):\n",
    "    def __init__(self, n_estimators=10, min_samples_leaf=3, \n",
    "    max_features=0.3, oob_score=False):\n",
    "        super().__init__(n_estimators, oob_score=oob_score, min_samples_leaf=min_samples_leaf, max_features=max_features)\n",
    "        #self.trees = ...\n",
    "\n",
    "    def predict(self, X_test) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Given a 2D nxp array with one or more records, compute the weighted average\n",
    "        prediction from all trees in this forest. Weight each trees prediction by\n",
    "        the number of observations in the leaf making that prediction.  Return a 1D vector\n",
    "        with the predictions for each input record of X_test.\n",
    "        \"\"\"\n",
    "        \n",
    "        prediction_leaves=[]\n",
    "        weighted_predictions=[]\n",
    "        count_leaves=[]\n",
    "\n",
    "        for tree in self.trees:\n",
    "\n",
    "            leaves=tree.predict(X_test)\n",
    "            prediction_leaves.append(leaves)\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(self.n_estimators):\n",
    "\n",
    "            weighted_predictions.append([leaf.prediction*leaf.n for leaf in prediction_leaves[i]])\n",
    "            count_leaves.append([leaf.n for leaf in prediction_leaves[i]])\n",
    "\n",
    "        weighted_arr=np.array(weighted_predictions)\n",
    "        weighted_pred_sum=np.sum(weighted_arr,axis=0)\n",
    "        count_leaves_arr=np.array(count_leaves)\n",
    "        leaves_sum_count=np.sum(count_leaves_arr,axis=0)\n",
    "\n",
    "        final_prediction_array=weighted_pred_sum/leaves_sum_count\n",
    "\n",
    "        return final_prediction_array\n",
    "    \n",
    "      \n",
    "    def score(self, X_test, y_test) -> float:\n",
    "        \"\"\"\n",
    "        Given a 2D nxp X_test array and 1D nx1 y_test array with one or more records,\n",
    "        collect the prediction for each record and then compute R^2 on that and y_test.\n",
    "        \"\"\"\n",
    "        y_pred = self.predict(X_test)\n",
    "        return r2_score(y_test, y_pred)\n",
    "        \n",
    "class RandomForestClassifier621(RandomForest621):\n",
    "    def __init__(self, n_estimators=10, min_samples_leaf=3, \n",
    "    max_features=0.3, oob_score=False):\n",
    "        super().__init__(n_estimators, oob_score=oob_score)\n",
    "        n_estimators = n_estimators\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        #self.trees = ...\n",
    "\n",
    "    def predict(self, X_test) -> np.ndarray:\n",
    "        \n",
    "        prediction_leaves=[]\n",
    "        #weighted_predictions=[]\n",
    "        #count_leaves=[]\n",
    "        list_y_vals=[]\n",
    "        final_list=[]\n",
    "\n",
    "        for tree in self.trees:\n",
    "\n",
    "            leaves=tree.predict(X_test)\n",
    "            prediction_leaves.append(leaves)\n",
    "            \n",
    "        \n",
    "\n",
    "        for i in range(self.n_estimators):\n",
    "\n",
    "            list_y_vals.append([leaf.y_vals for leaf in prediction_leaves[i]])\n",
    "            \n",
    "        for j in range(len(X_test)):\n",
    "\n",
    "\n",
    "            final_list.append(np.concatenate([list_y_vals[i][j] for i in range(n_estimators)]))\n",
    "            \n",
    "           \n",
    "        return np.array([stats.mode(final_list[i])[0][0] for i in range(len(X_test))])\n",
    "        \n",
    "        \n",
    "    def score(self, X_test, y_test) -> float:\n",
    "        \"\"\"\n",
    "        Given a 2D nxp X_test array and 1D nx1 y_test array with one or more records,\n",
    "        collect the predicted class for each record and then compute accuracy between\n",
    "        that and y_test.\n",
    "        \"\"\"\n",
    "        \n",
    "        y_pred = self.predict(X_test)\n",
    "        return accuracy_score(y_test, y_pred)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b366adc-49c4-4006-9f87-af86275ef3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import \\\n",
    "    load_boston, load_iris, load_diabetes, load_wine, \\\n",
    "    load_breast_cancer, fetch_california_housing\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import inspect\n",
    "\n",
    "#X, y = load_boston(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f36d796-8846-44d6-a570-0163d559849b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#X, y = load_wine(return_X_y=True)\n",
    "X, y = load_boston(return_X_y=True)\n",
    "#X, y = load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56f7a6e5-8490-4346-bc24-611f07ca153f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "            train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c4c40f5-b7f0-4a5a-bb2e-3fe2a507a324",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_leaf=3\n",
    "max_features=0.3\n",
    "oob=False \n",
    "n_estimators=18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "399dcb0b-7527-4149-bcdd-2d9573bbff9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf = RandomForestClassifier621(n_estimators=n_estimators, min_samples_leaf=min_samples_leaf, max_features=max_features, oob_score=oob)\n",
    "rf= RandomForestRegressor621(n_estimators=n_estimators, min_samples_leaf=min_samples_leaf, max_features=max_features, oob_score=oob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebd0b639-f2c7-43f5-b2d8-4b3c9f815710",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akshaypamnani/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/akshaypamnani/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36mRandomForest621.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m#trees_dict[i]=tree\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrees\u001b[38;5;241m.\u001b[39mappend(tree)\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moob_score_\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_oob_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, RandomForestClassifier621):\n\u001b[1;32m     74\u001b[0m     tree\u001b[38;5;241m=\u001b[39mClassifierTree621(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_leaf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_features, oob_index)\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36mRandomForest621.compute_oob_score\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m#Have to deal with missing values\u001b[39;00m\n\u001b[1;32m     40\u001b[0m oob_predictions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(oob_index_preds\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[0;32m---> 41\u001b[0m oob_predictions\u001b[38;5;241m=\u001b[39m\u001b[43moob_predictions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m~\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misnan\u001b[49m\u001b[43m(\u001b[49m\u001b[43moob_predictions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     42\u001b[0m y_filtered\u001b[38;5;241m=\u001b[39my[np\u001b[38;5;241m.\u001b[39mwhere(\u001b[38;5;241m~\u001b[39mnp\u001b[38;5;241m.\u001b[39misnan(oob_predictions))]\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrees[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mscore(oob_predictions,y_filtered)\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96d2517-7396-4eeb-befb-fc383b6a6312",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
